{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies_raw = pd.read_csv('../movie-data.csv')\n",
    "users_raw = pd.read_csv('../users-data.csv')\n",
    "ratings_raw = pd.read_csv('../ratings-data.csv')\n",
    "\n",
    "users_raw.set_index('user_id', inplace=True)\n",
    "movies_raw.set_index('movie_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>if+you+could+only+cook+1935</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>tt0026519</td>\n",
       "      <td>en</td>\n",
       "      <td>If You Could Only Cook</td>\n",
       "      <td>An auto engineer (Herbert Marshall) and a prof...</td>\n",
       "      <td>0.430813</td>\n",
       "      <td>['Columbia Pictures']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1935-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>['English']</td>\n",
       "      <td>If You Could Only Cook</td>\n",
       "      <td>126083</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the+tattooed+widow+1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>tt0120299</td>\n",
       "      <td>sv</td>\n",
       "      <td>Den tatuerade änkan</td>\n",
       "      <td>Ester is the perfect grandmother everyone expe...</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1998-03-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Tattooed Widow</td>\n",
       "      <td>80059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride+and+prejudice+1980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>tt0078672</td>\n",
       "      <td>en</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Mrs. Bennet is determined to find husbands for...</td>\n",
       "      <td>0.073979</td>\n",
       "      <td>['Australian Broadcasting Corporation', 'Briti...</td>\n",
       "      <td>['United Kingdom', 'Australia']</td>\n",
       "      <td>1980-01-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265</td>\n",
       "      <td>['English']</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>77172</td>\n",
       "      <td>6.8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flodder+1986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>tt0091060</td>\n",
       "      <td>fr</td>\n",
       "      <td>Flodder</td>\n",
       "      <td>A low-class a-social family ends up in a rich ...</td>\n",
       "      <td>6.702840</td>\n",
       "      <td>['First Floor Features']</td>\n",
       "      <td>['Netherlands']</td>\n",
       "      <td>1986-12-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111</td>\n",
       "      <td>['Nederlands']</td>\n",
       "      <td>Flodder</td>\n",
       "      <td>10570</td>\n",
       "      <td>6.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold+turkey+1971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>tt0066927</td>\n",
       "      <td>en</td>\n",
       "      <td>Cold Turkey</td>\n",
       "      <td>Reverend Brooks leads the town in a contest to...</td>\n",
       "      <td>0.609080</td>\n",
       "      <td>['Tandem Productions', 'DFI']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1971-02-19</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>99</td>\n",
       "      <td>['English']</td>\n",
       "      <td>Cold Turkey</td>\n",
       "      <td>42493</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             budget                 genres    imdb_id  \\\n",
       "movie_id                                                                \n",
       "if+you+could+only+cook+1935     0.0  ['Comedy', 'Romance']  tt0026519   \n",
       "the+tattooed+widow+1998         0.0                     []  tt0120299   \n",
       "pride+and+prejudice+1980        0.0              ['Drama']  tt0078672   \n",
       "flodder+1986                    0.0             ['Comedy']  tt0091060   \n",
       "cold+turkey+1971                0.0             ['Comedy']  tt0066927   \n",
       "\n",
       "                            original_language          original_title  \\\n",
       "movie_id                                                                \n",
       "if+you+could+only+cook+1935                en  If You Could Only Cook   \n",
       "the+tattooed+widow+1998                    sv     Den tatuerade änkan   \n",
       "pride+and+prejudice+1980                   en     Pride and Prejudice   \n",
       "flodder+1986                               fr                 Flodder   \n",
       "cold+turkey+1971                           en             Cold Turkey   \n",
       "\n",
       "                                                                      overview  \\\n",
       "movie_id                                                                         \n",
       "if+you+could+only+cook+1935  An auto engineer (Herbert Marshall) and a prof...   \n",
       "the+tattooed+widow+1998      Ester is the perfect grandmother everyone expe...   \n",
       "pride+and+prejudice+1980     Mrs. Bennet is determined to find husbands for...   \n",
       "flodder+1986                 A low-class a-social family ends up in a rich ...   \n",
       "cold+turkey+1971             Reverend Brooks leads the town in a contest to...   \n",
       "\n",
       "                             popularity  \\\n",
       "movie_id                                  \n",
       "if+you+could+only+cook+1935    0.430813   \n",
       "the+tattooed+widow+1998        0.012333   \n",
       "pride+and+prejudice+1980       0.073979   \n",
       "flodder+1986                   6.702840   \n",
       "cold+turkey+1971               0.609080   \n",
       "\n",
       "                                                          production_companies  \\\n",
       "movie_id                                                                         \n",
       "if+you+could+only+cook+1935                              ['Columbia Pictures']   \n",
       "the+tattooed+widow+1998                                                     []   \n",
       "pride+and+prejudice+1980     ['Australian Broadcasting Corporation', 'Briti...   \n",
       "flodder+1986                                          ['First Floor Features']   \n",
       "cold+turkey+1971                                 ['Tandem Productions', 'DFI']   \n",
       "\n",
       "                                        production_countries release_date  \\\n",
       "movie_id                                                                    \n",
       "if+you+could+only+cook+1935     ['United States of America']   1935-12-30   \n",
       "the+tattooed+widow+1998                                   []   1998-03-10   \n",
       "pride+and+prejudice+1980     ['United Kingdom', 'Australia']   1980-01-13   \n",
       "flodder+1986                                 ['Netherlands']   1986-12-17   \n",
       "cold+turkey+1971                ['United States of America']   1971-02-19   \n",
       "\n",
       "                                revenue  runtime spoken_languages  \\\n",
       "movie_id                                                            \n",
       "if+you+could+only+cook+1935         0.0       72      ['English']   \n",
       "the+tattooed+widow+1998             0.0        0               []   \n",
       "pride+and+prejudice+1980            0.0      265      ['English']   \n",
       "flodder+1986                        0.0      111   ['Nederlands']   \n",
       "cold+turkey+1971             11000000.0       99      ['English']   \n",
       "\n",
       "                                              title  tmdb_id  vote_average  \\\n",
       "movie_id                                                                     \n",
       "if+you+could+only+cook+1935  If You Could Only Cook   126083           6.8   \n",
       "the+tattooed+widow+1998          The Tattooed Widow    80059           0.0   \n",
       "pride+and+prejudice+1980        Pride and Prejudice    77172           6.8   \n",
       "flodder+1986                                Flodder    10570           6.6   \n",
       "cold+turkey+1971                        Cold Turkey    42493           7.5   \n",
       "\n",
       "                             vote_count  \n",
       "movie_id                                 \n",
       "if+you+could+only+cook+1935           4  \n",
       "the+tattooed+widow+1998               0  \n",
       "pride+and+prejudice+1980             14  \n",
       "flodder+1986                         32  \n",
       "cold+turkey+1971                      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_multilabel_binarizer_cols(df, col_options):\n",
    "    binarizers = []\n",
    "    sparse_df = df.copy()\n",
    "    for col_option in col_options:\n",
    "        col_name = col_option.get('name')\n",
    "#         is_col_arraystr = col_option.get('is_col_arraystr', False)\n",
    "#         is_single_char = col_option.get('is_single_char',False)\n",
    "        new_col, mlb = create_multilabel_binarizer(sparse_df[col_name])\n",
    "        \n",
    "        binarizers.append((col_name,mlb))\n",
    "        print('Column: {NAME} Values: {OPTIONS}'.format(NAME=col_name, OPTIONS=mlb.classes_))\n",
    "\n",
    "        sparse_df = pd.concat([sparse_df, new_col],axis=1)\n",
    "        sparse_df.drop(col_name, axis=1, inplace=True)\n",
    "    \n",
    "    return sparse_df, binarizers\n",
    "\n",
    "def create_multilabel_binarizer(column):\n",
    "    transformed_column = column.copy()\n",
    "\n",
    "    transformed_column.loc[transformed_column.isnull()] = transformed_column.loc[\n",
    "        transformed_column.isnull()\n",
    "    ].apply(lambda x: '[]')\n",
    "    transformed_column = transformed_column.apply(parse_arraystr)\n",
    "#     elif is_single_char:\n",
    "#         transformed_colum = transformed_column\n",
    "#     else:\n",
    "#         transformed_column = transformed_column\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(transformed_column)\n",
    "    return pd.DataFrame(mlb.transform(transformed_column),columns=mlb.classes_), mlb\n",
    "\n",
    "    \n",
    "def parse_arraystr(str):\n",
    "    str_without_brackets = str.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    str_without_quotes = str_without_brackets.replace(\"'\",\"\")\n",
    "    str_without_spaces = str_without_quotes.replace(\" \",\"\")\n",
    "    return np.array(str_without_spaces.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: genres Values: ['' 'Action' 'Adventure' 'Animation' 'Comedy' 'Crime' 'Documentary'\n",
      " 'Drama' 'Family' 'Fantasy' 'Foreign' 'History' 'Horror' 'Music' 'Mystery'\n",
      " 'Romance' 'ScienceFiction' 'TVMovie' 'Thriller' 'War' 'Western']\n",
      "Column: production_countries Values: ['' '\"CoteDIvoire\"' 'Afghanistan' 'Algeria' 'Angola' 'Argentina' 'Armenia'\n",
      " 'Aruba' 'Australia' 'Austria' 'Bahamas' 'Belgium' 'Bhutan'\n",
      " 'BosniaandHerzegovina' 'Botswana' 'Brazil' 'Bulgaria' 'BurkinaFaso'\n",
      " 'Cameroon' 'Canada' 'Chile' 'China' 'Colombia' 'Congo' 'CostaRica'\n",
      " 'Croatia' 'Cuba' 'Cyprus' 'CzechRepublic' 'Czechoslovakia' 'Denmark'\n",
      " 'DominicanRepublic' 'Ecuador' 'Egypt' 'Estonia' 'Finland' 'France'\n",
      " 'Georgia' 'Germany' 'Greece' 'HongKong' 'Hungary' 'Iceland' 'India'\n",
      " 'Indonesia' 'Iran' 'Iraq' 'Ireland' 'Israel' 'Italy' 'Jamaica' 'Japan'\n",
      " 'Kazakhstan' 'Latvia' 'Lebanon' 'LibyanArabJamahiriya' 'Liechtenstein'\n",
      " 'Lithuania' 'Luxembourg' 'Macedonia' 'Malaysia' 'Malta' 'Mexico' 'Monaco'\n",
      " 'Mongolia' 'Morocco' 'Namibia' 'Nepal' 'Netherlands' 'NewZealand'\n",
      " 'NorthKorea' 'Norway' 'Pakistan' 'PalestinianTerritory' 'Panama'\n",
      " 'Paraguay' 'Peru' 'Philippines' 'Poland' 'Portugal' 'PuertoRico'\n",
      " 'Romania' 'Russia' 'Senegal' 'Serbia' 'SerbiaandMontenegro' 'Singapore'\n",
      " 'Slovakia' 'Slovenia' 'SouthAfrica' 'SouthKorea' 'SovietUnion' 'Spain'\n",
      " 'Sweden' 'Switzerland' 'Taiwan' 'Tajikistan' 'Thailand'\n",
      " 'TrinidadandTobago' 'Tunisia' 'Turkey' 'Ukraine' 'UnitedArabEmirates'\n",
      " 'UnitedKingdom' 'UnitedStatesofAmerica' 'Uruguay' 'Uzbekistan' 'Vietnam'\n",
      " 'Zimbabwe']\n",
      "Column: spoken_languages Values: ['' 'Afrikaans' 'Azərbaycan' 'Bahasaindonesia' 'Bahasamelayu' 'Bamanankan'\n",
      " 'Bokmål' 'Bosanski' 'Català' 'Cymraeg' 'Dansk' 'Deutsch' 'Eesti'\n",
      " 'English' 'Español' 'Esperanto' 'Français' 'Gaeilge' 'Galego' 'Hrvatski'\n",
      " 'Italiano' 'Kinyarwanda' 'Kiswahili' 'Latin' 'Latviešu' 'Magyar' 'Malti'\n",
      " 'Nederlands' 'NoLanguage' 'Norsk' 'Polski' 'Português' 'Pусский' 'Română'\n",
      " 'Slovenčina' 'Slovenščina' 'Somali' 'Srpski' 'TiếngViệt' 'Türkçe' 'Wolof'\n",
      " 'euskera' 'isiZulu' 'shqip' 'suomi' 'svenska' 'Íslenska' 'Český'\n",
      " 'ελληνικά' 'Український' 'беларускаямова' 'българскиезик' 'қазақ'\n",
      " 'עִבְרִית' 'اردو' 'العربية' 'فارسی' 'پښتو' 'हिन्दी' 'বাংলা' 'ਪੰਜਾਬੀ'\n",
      " 'தமிழ்' 'ภาษาไทย' 'ქართული' '广州话/廣州話' '日本語' '普通话' '한국어/조선말']\n",
      "Column: gender Values: ['F' 'M']\n",
      "Column: occupation Values: ['K-12student' 'academic/educator' 'artist' 'clerical/admin'\n",
      " 'college/gradstudent' 'customerservice' 'doctor/healthcare'\n",
      " 'executive/managerial' 'farmer' 'homemaker' 'lawyer'\n",
      " 'otherornotspecified' 'programmer' 'retired' 'sales/marketing'\n",
      " 'scientist' 'self-employed' 'technician/engineer' 'tradesman/craftsman'\n",
      " 'unemployed' 'writer']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>retired</th>\n",
       "      <th>sales/marketing</th>\n",
       "      <th>scientist</th>\n",
       "      <th>self-employed</th>\n",
       "      <th>technician/engineer</th>\n",
       "      <th>tradesman/craftsman</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>writer</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18519</th>\n",
       "      <td>sleepless+in+seattle+1993</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>tt0108160</td>\n",
       "      <td>en</td>\n",
       "      <td>Sleepless in Seattle</td>\n",
       "      <td>A young boy who tries to set his dad up on a d...</td>\n",
       "      <td>10.23490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18943</th>\n",
       "      <td>star+trek+generations+1994</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>tt0111280</td>\n",
       "      <td>en</td>\n",
       "      <td>Star Trek: Generations</td>\n",
       "      <td>Captain Jean-Luc Picard and the crew of the En...</td>\n",
       "      <td>8.10571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>pulp+fiction+1994</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>tt0110912</td>\n",
       "      <td>en</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>A burger-loving hit man, his philosophical par...</td>\n",
       "      <td>140.95000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20250</th>\n",
       "      <td>johnny+mnemonic+1995</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>tt0113481</td>\n",
       "      <td>en</td>\n",
       "      <td>Johnny Mnemonic</td>\n",
       "      <td>A data courier, literally carrying a data pack...</td>\n",
       "      <td>11.71590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18869</th>\n",
       "      <td>miracle+on+34th+street+1994</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt0110527</td>\n",
       "      <td>en</td>\n",
       "      <td>Miracle on 34th Street</td>\n",
       "      <td>A little girl discovers dreams can come true i...</td>\n",
       "      <td>5.83162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          movie_id  rating  user_id  age      budget  \\\n",
       "18519    sleepless+in+seattle+1993       4        8   30  21000000.0   \n",
       "18943   star+trek+generations+1994       3        8   30  38000000.0   \n",
       "17113            pulp+fiction+1994       5        8   30   8000000.0   \n",
       "20250         johnny+mnemonic+1995       1        8   30  25000000.0   \n",
       "18869  miracle+on+34th+street+1994       4        8   30         0.0   \n",
       "\n",
       "         imdb_id original_language          original_title  \\\n",
       "18519  tt0108160                en    Sleepless in Seattle   \n",
       "18943  tt0111280                en  Star Trek: Generations   \n",
       "17113  tt0110912                en            Pulp Fiction   \n",
       "20250  tt0113481                en         Johnny Mnemonic   \n",
       "18869  tt0110527                en  Miracle on 34th Street   \n",
       "\n",
       "                                                overview  popularity  ...  \\\n",
       "18519  A young boy who tries to set his dad up on a d...    10.23490  ...   \n",
       "18943  Captain Jean-Luc Picard and the crew of the En...     8.10571  ...   \n",
       "17113  A burger-loving hit man, his philosophical par...   140.95000  ...   \n",
       "20250  A data courier, literally carrying a data pack...    11.71590  ...   \n",
       "18869  A little girl discovers dreams can come true i...     5.83162  ...   \n",
       "\n",
       "      retired  sales/marketing  scientist self-employed  technician/engineer  \\\n",
       "18519       0                0          0             0                    0   \n",
       "18943       0                0          0             0                    0   \n",
       "17113       0                0          0             0                    0   \n",
       "20250       0                0          0             0                    0   \n",
       "18869       0                0          0             0                    0   \n",
       "\n",
       "       tradesman/craftsman  unemployed  writer  year  month  \n",
       "18519                    0           0       0  1993      6  \n",
       "18943                    0           0       0  1994     11  \n",
       "17113                    0           0       0  1994      9  \n",
       "20250                    0           0       0  1995      5  \n",
       "18869                    0           0       0  1994     11  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "ratings = ratings_raw.join(users_raw, on='user_id', how='left')\n",
    "ratings = ratings.join(movies_raw, on='movie_id', how='left')\n",
    "\n",
    "ratings, binarizers = transform_multilabel_binarizer_cols(ratings, [\n",
    "    {'name':'genres'},\n",
    "    {'name':'production_countries'},\n",
    "    {'name':'spoken_languages'},\n",
    "    {'name':'gender'},\n",
    "    {'name':'occupation'},\n",
    "])\n",
    "\n",
    "ratings = ratings.dropna(subset=['release_date'])\n",
    "ratings['year'] = ratings['release_date'].apply(lambda x: str(x)[:4])\n",
    "ratings['month'] = ratings['release_date'].apply(lambda x: str(x)[5:7])\n",
    "ratings = ratings.astype({'year':'int64', 'month':'int64'})\n",
    "ratings.drop('release_date', axis=1, inplace=True)\n",
    "\n",
    "ratings = ratings.sort_values(by=['user_id'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=110.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-3/pipeline_gen_1_idx_0_2020.07.11_01-36-47.pySVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...tile(input_matrix, SelectPercentile__percentile=27)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-3/pipeline_gen_3_idx_0_2020.07.11_01-39-24.py\n",
      "Skipped pipeline #46 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-3/pipeline_gen_4_idx_0_2020.07.11_01-44-26.py.05), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.45)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-3/pipeline_gen_5_idx_0_2020.07.11_01-48-43.py001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.45)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-3/pipeline_gen_6_idx_0_2020.07.11_01-49-15.py.05), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.45)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Skipped pipeline #73 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...rianceThreshold(input_matrix, VarianceThreshold__threshold=0.05), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.45)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #90 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #92 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 8 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-3/pipeline_gen_8_idx_0_2020.07.11_01-59-18.py.05), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.3)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "Skipped pipeline #98 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #101 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 9 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...rianceThreshold(input_matrix, VarianceThreshold__threshold=0.05), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.3)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 10 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-3/pipeline_gen_10_idx_0_2020.07.11_02-09-14.py05), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(generations=10,\n",
       "              log_file=<ipykernel.iostream.OutStream object at 0x10a49efd0>,\n",
       "              n_jobs=8,\n",
       "              periodic_checkpoint_folder='../tpot-intermediate-save-3/',\n",
       "              population_size=10, random_state=42,\n",
       "              template='Selector-Transformer-Regressor', verbosity=3,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "\n",
    "X_train = ratings.drop(['movie_id','imdb_id','tmdb_id','user_id','title','overview', 'original_language',# 'genres', 'production_countries', 'spoken_languages', 'gender','occupation',\n",
    "                        'original_title','production_companies','rating'], axis=1).dropna()\n",
    "\n",
    "\n",
    "X_train = X_train\n",
    "y_train = ratings['rating']\n",
    "\n",
    "pipeline_optimizer = TPOTRegressor(generations=10, population_size=10, verbosity=3, random_state=42,\n",
    "                                   template='Selector-Transformer-Regressor', n_jobs=8,\n",
    "                                   warm_start=True, periodic_checkpoint_folder='../tpot-intermediate-save-3/')\n",
    "pipeline_optimizer.fit(X_train.head(10000),y_train.head(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9845655731739391"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.score(X_train[10001:20000], y_train[10001:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=550.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #3 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #9 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #17 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #20 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #22 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #31 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #33 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #38 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #42 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #45 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #49 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #57 due to time out. Continuing to the next pipeline.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #88 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #91 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #95 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #97 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #100 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #102 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #106 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #118 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-2/pipeline_gen_1_idx_0_2020.07.09_09-45-26.py=36)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "Skipped pipeline #136 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #142 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...(SelectPercentile(input_matrix, SelectPercentile__percentile=36)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #185 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #187 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #191 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #193 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #211 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #221 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #223 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...(SelectPercentile(input_matrix, SelectPercentile__percentile=36)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #240 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #249 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #251 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #263 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #266 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #277 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #281 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #283 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...(SelectPercentile(input_matrix, SelectPercentile__percentile=36)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #297 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #303 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #306 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #308 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #325 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #330 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #332 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #335 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #338 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #343 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...(SelectPercentile(input_matrix, SelectPercentile__percentile=36)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-2/pipeline_gen_6_idx_0_2020.07.09_17-06-33.py22)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=17)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-2/pipeline_gen_7_idx_0_2020.07.09_17-30-01.py=12)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 8 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-2/pipeline_gen_8_idx_0_2020.07.09_17-53-25.py12)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=15, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 9 - Current Pareto front scores:\n",
      "Periodic pipeline was not saved, probably saved before...SelectPercentile(input_matrix, SelectPercentile__percentile=12)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=15, DecisionTreeRegressor__min_samples_split=5)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "\n",
      "Generation 10 - Current Pareto front scores:\n",
      "Saving periodic pipeline from pareto front to ../tpot-intermediate-save-2/pipeline_gen_10_idx_0_2020.07.09_18-37-45.py9)), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict='TPOT light', generations=10,\n",
       "              log_file=<ipykernel.iostream.OutStream object at 0x10fe7cd60>,\n",
       "              periodic_checkpoint_folder='../tpot-intermediate-save-2/',\n",
       "              population_size=50, random_state=42,\n",
       "              template='Selector-Transformer-Regressor', verbosity=3,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline_optimizer_nn = TPOTRegressor(generations=10, population_size=50, verbosity=3, random_state=42,\n",
    "                                      template='Selector-Transformer-Regressor',config_dict=\"TPOT light\",# n_jobs=4,\n",
    "                                     warm_start=True, periodic_checkpoint_folder='../tpot-intermediate-save-2/')\n",
    "pipeline_optimizer_nn.fit(X_train.head(500000),y_train.head(500000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9647899279603104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer_nn.score(X_train[500001:700000], y_train[500001:700000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
