{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPFN1yMzpWbB"
   },
   "source": [
    "# TPOT Explained with Movies\n",
    "\n",
    "In this example, we will walk through a simplified machine learning problem to explore the TPOT tool. \n",
    "For more information on TPOT check out their [documentation](https://epistasislab.github.io/tpot/). \n",
    "For more information about this example please refer to my [medium article]().\n",
    "### What is TPOT?\n",
    "TPOT is an AutoML tool. This means that it is designed to automate the creation of a machine learning pipeline. TPOT is built on top of [scikit-learn](https://scikit-learn.org/stable/) a popular python library for machine learning. Therefore, the syntax it uses and pipelines it generates should be easy to understand for those with a basic understanding of scikit-learn.\n",
    "\n",
    "Rather than manually running multiple experiments involving scikit-learn grid searches TPOT will automatically generate many pipelines and compare them. This can reduce the manual time needed to design and evaluate these experiments. \n",
    "\n",
    "### Our Scenario\n",
    "In this simple scenario, we are building a recommendation system for movies based on a streaming service. I used a Kafka service that streamed data about movie files watched by users and movie ratings they submitted. The original data had ~1 million users and ~27 thousand movies. I streamed this data, parsed it, and saved it in a database. \n",
    "\n",
    "In this scenario, we are going to use data regarding the user and movie to predict how the user would rate the movie on a scale of 1-5. This can be used in a recommendation service to sort the highest predicted ratings and recommend a movie.\n",
    "\n",
    "## Let's Get Started!\n",
    "First, we are going to start by loading the data.\n",
    "\n",
    "## Loading the Data\n",
    "The CSV files stored in the repo are a snapshot of our database tables at one point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1WCPpf6pIJO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies_raw = pd.read_csv('../movie-data.csv')\n",
    "users_raw = pd.read_csv('../users-data.csv')\n",
    "ratings_raw = pd.read_csv('../ratings-data.csv')\n",
    "\n",
    "users_raw.set_index('user_id', inplace=True)\n",
    "movies_raw.set_index('movie_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TB54c7BLqFBo"
   },
   "source": [
    "### Movie Data\n",
    "Below we can see the movie data returned. One thing to note is this data comes from external sources. The data is based on TMDB or IMDB. Therefore, the vote_average is not the ratings from the stream. We can see that several columns are not going to be useful and some will need to be transformed even before using TPOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "IIOw6WnmqF-0",
    "outputId": "2664f8b2-09e6-4d3d-9bc3-69ddc3a6f895"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>if+you+could+only+cook+1935</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>tt0026519</td>\n",
       "      <td>en</td>\n",
       "      <td>If You Could Only Cook</td>\n",
       "      <td>An auto engineer (Herbert Marshall) and a prof...</td>\n",
       "      <td>0.430813</td>\n",
       "      <td>['Columbia Pictures']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1935-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>['English']</td>\n",
       "      <td>If You Could Only Cook</td>\n",
       "      <td>126083</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the+tattooed+widow+1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>tt0120299</td>\n",
       "      <td>sv</td>\n",
       "      <td>Den tatuerade Ã¤nkan</td>\n",
       "      <td>Ester is the perfect grandmother everyone expe...</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1998-03-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Tattooed Widow</td>\n",
       "      <td>80059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride+and+prejudice+1980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>tt0078672</td>\n",
       "      <td>en</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Mrs. Bennet is determined to find husbands for...</td>\n",
       "      <td>0.073979</td>\n",
       "      <td>['Australian Broadcasting Corporation', 'Briti...</td>\n",
       "      <td>['United Kingdom', 'Australia']</td>\n",
       "      <td>1980-01-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265</td>\n",
       "      <td>['English']</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>77172</td>\n",
       "      <td>6.8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flodder+1986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>tt0091060</td>\n",
       "      <td>fr</td>\n",
       "      <td>Flodder</td>\n",
       "      <td>A low-class a-social family ends up in a rich ...</td>\n",
       "      <td>6.702840</td>\n",
       "      <td>['First Floor Features']</td>\n",
       "      <td>['Netherlands']</td>\n",
       "      <td>1986-12-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111</td>\n",
       "      <td>['Nederlands']</td>\n",
       "      <td>Flodder</td>\n",
       "      <td>10570</td>\n",
       "      <td>6.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold+turkey+1971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>tt0066927</td>\n",
       "      <td>en</td>\n",
       "      <td>Cold Turkey</td>\n",
       "      <td>Reverend Brooks leads the town in a contest to...</td>\n",
       "      <td>0.609080</td>\n",
       "      <td>['Tandem Productions', 'DFI']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1971-02-19</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>99</td>\n",
       "      <td>['English']</td>\n",
       "      <td>Cold Turkey</td>\n",
       "      <td>42493</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             budget                 genres    imdb_id  \\\n",
       "movie_id                                                                \n",
       "if+you+could+only+cook+1935     0.0  ['Comedy', 'Romance']  tt0026519   \n",
       "the+tattooed+widow+1998         0.0                     []  tt0120299   \n",
       "pride+and+prejudice+1980        0.0              ['Drama']  tt0078672   \n",
       "flodder+1986                    0.0             ['Comedy']  tt0091060   \n",
       "cold+turkey+1971                0.0             ['Comedy']  tt0066927   \n",
       "\n",
       "                            original_language          original_title  \\\n",
       "movie_id                                                                \n",
       "if+you+could+only+cook+1935                en  If You Could Only Cook   \n",
       "the+tattooed+widow+1998                    sv     Den tatuerade Ã¤nkan   \n",
       "pride+and+prejudice+1980                   en     Pride and Prejudice   \n",
       "flodder+1986                               fr                 Flodder   \n",
       "cold+turkey+1971                           en             Cold Turkey   \n",
       "\n",
       "                                                                      overview  \\\n",
       "movie_id                                                                         \n",
       "if+you+could+only+cook+1935  An auto engineer (Herbert Marshall) and a prof...   \n",
       "the+tattooed+widow+1998      Ester is the perfect grandmother everyone expe...   \n",
       "pride+and+prejudice+1980     Mrs. Bennet is determined to find husbands for...   \n",
       "flodder+1986                 A low-class a-social family ends up in a rich ...   \n",
       "cold+turkey+1971             Reverend Brooks leads the town in a contest to...   \n",
       "\n",
       "                             popularity  \\\n",
       "movie_id                                  \n",
       "if+you+could+only+cook+1935    0.430813   \n",
       "the+tattooed+widow+1998        0.012333   \n",
       "pride+and+prejudice+1980       0.073979   \n",
       "flodder+1986                   6.702840   \n",
       "cold+turkey+1971               0.609080   \n",
       "\n",
       "                                                          production_companies  \\\n",
       "movie_id                                                                         \n",
       "if+you+could+only+cook+1935                              ['Columbia Pictures']   \n",
       "the+tattooed+widow+1998                                                     []   \n",
       "pride+and+prejudice+1980     ['Australian Broadcasting Corporation', 'Briti...   \n",
       "flodder+1986                                          ['First Floor Features']   \n",
       "cold+turkey+1971                                 ['Tandem Productions', 'DFI']   \n",
       "\n",
       "                                        production_countries release_date  \\\n",
       "movie_id                                                                    \n",
       "if+you+could+only+cook+1935     ['United States of America']   1935-12-30   \n",
       "the+tattooed+widow+1998                                   []   1998-03-10   \n",
       "pride+and+prejudice+1980     ['United Kingdom', 'Australia']   1980-01-13   \n",
       "flodder+1986                                 ['Netherlands']   1986-12-17   \n",
       "cold+turkey+1971                ['United States of America']   1971-02-19   \n",
       "\n",
       "                                revenue  runtime spoken_languages  \\\n",
       "movie_id                                                            \n",
       "if+you+could+only+cook+1935         0.0       72      ['English']   \n",
       "the+tattooed+widow+1998             0.0        0               []   \n",
       "pride+and+prejudice+1980            0.0      265      ['English']   \n",
       "flodder+1986                        0.0      111   ['Nederlands']   \n",
       "cold+turkey+1971             11000000.0       99      ['English']   \n",
       "\n",
       "                                              title  tmdb_id  vote_average  \\\n",
       "movie_id                                                                     \n",
       "if+you+could+only+cook+1935  If You Could Only Cook   126083           6.8   \n",
       "the+tattooed+widow+1998          The Tattooed Widow    80059           0.0   \n",
       "pride+and+prejudice+1980        Pride and Prejudice    77172           6.8   \n",
       "flodder+1986                                Flodder    10570           6.6   \n",
       "cold+turkey+1971                        Cold Turkey    42493           7.5   \n",
       "\n",
       "                             vote_count  \n",
       "movie_id                                 \n",
       "if+you+could+only+cook+1935           4  \n",
       "the+tattooed+widow+1998               0  \n",
       "pride+and+prejudice+1980             14  \n",
       "flodder+1986                         32  \n",
       "cold+turkey+1971                      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umnE6Ql4qdKF"
   },
   "source": [
    "### User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "MQ7ECKwFqKnK",
    "outputId": "506e74d6-9247-40e1-e98f-d3e255bb62e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800720</th>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577694</th>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>college/grad student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207937</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>college/grad student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584780</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>executive/managerial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149240</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>sales/marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender            occupation\n",
       "user_id                                  \n",
       "800720    42      M             scientist\n",
       "577694    31      M  college/grad student\n",
       "207937    28      F  college/grad student\n",
       "584780    33      M  executive/managerial\n",
       "149240    34      F       sales/marketing"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NH62P5kJqgQJ"
   },
   "source": [
    "### Rating Data\n",
    "This table contains the labels for our data. It tells us the rating a user gave a specific movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "iiyEjAyuqjzl",
    "outputId": "f0cb6e96-6deb-420b-f8f8-be087ea49368"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jackass+the+movie+2002</td>\n",
       "      <td>4</td>\n",
       "      <td>615847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mission+impossible+iii+2006</td>\n",
       "      <td>4</td>\n",
       "      <td>284854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good+will+hunting+1997</td>\n",
       "      <td>5</td>\n",
       "      <td>792329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy+gilmore+1996</td>\n",
       "      <td>3</td>\n",
       "      <td>709941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moulin+rouge+2001</td>\n",
       "      <td>3</td>\n",
       "      <td>531076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie_id  rating  user_id\n",
       "0       jackass+the+movie+2002       4   615847\n",
       "1  mission+impossible+iii+2006       4   284854\n",
       "2       good+will+hunting+1997       5   792329\n",
       "3           happy+gilmore+1996       3   709941\n",
       "4            moulin+rouge+2001       3   531076"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vok1UNDhql4g"
   },
   "source": [
    "## Data Cleaning\n",
    "Before we pass the data into TPOT we should do some basic cleaning of the data. Currently, TPOT works with numerical data although there is some work being done to add some auto [data cleaning](https://github.com/rhiever/datacleaner/issues/1). Therefore, we need to transform some of our data into a format that TPOT will understand. The best way to do this is with scikit-learn [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [column transformers](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). This makes the transformations a repeatable process, which is important because we are going to need to apply the same transformations when a making a prediction in our hypothetical production system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8iyxmbrzxJV"
   },
   "source": [
    "### Categorical Features\n",
    "Some of our features are categorical, such as `genres`. I decided to turn the categorical features into binary features. For example, instead of `genres`, I would have `Action` with a value of `1` if the movie was an action movie and `0` if it was not an action movie.\n",
    "\n",
    "To do this, I created a pipeline to apply scikit-learn's [MultiLabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html?highlight=multilabel%20binarizer#sklearn.preprocessing.MultiLabelBinarizer). First I needed to turn the cells of the columns into arrays instead of strings that resembled arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVenTsJItaap"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class MultiLabelStringToArray(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This shapes the data to be passed into the MultiLabelBinarizer. It takes\n",
    "    columns that are array-like strings and turns them into arrays.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        df = X.copy()\n",
    "        for column_name in df.columns:\n",
    "            df[column_name] = self._transform_column_to_array(df[column_name])\n",
    "        return df\n",
    "\n",
    "    def _transform_column_to_array(self, pd_column):\n",
    "        transformed_column = pd_column.copy()\n",
    "        \n",
    "        # replace null cells with empty array\n",
    "        transformed_column.loc[transformed_column.isnull()] = transformed_column.loc[\n",
    "            transformed_column.isnull()\n",
    "        ].apply(lambda x: '[]')\n",
    "\n",
    "        # parse string into array\n",
    "        transformed_column = transformed_column.apply(self._parse_arraystr)\n",
    "        return transformed_column\n",
    "\n",
    "    def _parse_arraystr(self, str):\n",
    "        \"\"\"\n",
    "        Applies a number of rules to turn an array looking string into an array\n",
    "          - remove brackets\n",
    "          - remove quotes\n",
    "          - remove extra spaces\n",
    "          - deliminate by comma\n",
    "          - remove empty string entries in the array\n",
    "        \"\"\"\n",
    "        str_without_brackets = str.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        str_without_quotes = str_without_brackets.replace(\"'\",\"\")\n",
    "        str_without_spaces = str_without_quotes.replace(\" \",\"\")\n",
    "        list_with_empties = str_without_spaces.split(',')\n",
    "        if '' in list_with_empties:\n",
    "            while(\"\" in list_with_empties) : \n",
    "                list_with_empties.remove(\"\") \n",
    "        return np.array(list_with_empties)\n",
    "    \n",
    "class MultiLabelBinarizerTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This tranformer creates a MultiLabelBinarizer for every column passed in.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mlbs = {}\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the MultiLabelBinarizer to the data passed in\"\"\"\n",
    "        df = X.copy()\n",
    "        for column_name in df.columns:\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(df[column_name])\n",
    "            # Uncomment the following line if you want to print out the values\n",
    "            # that the MultiLabelbinarizer discovered.\n",
    "            #print('Column: {NAME} Values: {VALUES}'.format(NAME=column_name, VALUES=mlb.classes_))\n",
    "            self.mlbs[column_name] = mlb\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Returns a dataframe with the binarized columns. When applied in a\n",
    "        ColumnTransformer this will effectively remove the original column and \n",
    "        replace it with the binary columns\n",
    "        \"\"\"\n",
    "        df = X.copy()\n",
    "        binarized_cols = pd.DataFrame()\n",
    "        for column_name in df.columns:\n",
    "            mlb = self.mlbs.get(column_name)\n",
    "            new_cols = pd.DataFrame(mlb.transform(df[column_name]),columns=mlb.classes_)\n",
    "            binarized_cols = pd.concat([binarized_cols, new_cols], axis=1)\n",
    "        return binarized_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fO3EidIKwtHZ"
   },
   "source": [
    "### Date Features\n",
    "We have a `release_date` feature; however, it is currently stored as a string so we want to extract meaningful data from the string. Since I do not believe that the day has much impact on how a user would rate something I am going to leave it out. I think the year could have some impact because users could be more excited by new movies or our streaming service might only contain very popular old movies. Also, I think the month could be helpful. It could discover that users are more likely to rate a movie highly if it is released during \"Oscar season\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5Q2Nzr5xiJN"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ExtractReleaseDateFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This transformer takes a column with a date string formatted as \n",
    "    'YYYY-mm-dd', extracts the year and month, and returns a DataFrame with\n",
    "    those columns.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Returns a dataframe with the year and month as integer fields. When \n",
    "        applied in a ColumnTransformer this will effectively remove the\n",
    "        original column and replace it with the new columns.\n",
    "        \"\"\"\n",
    "        df = X.copy()\n",
    "\n",
    "        # fill nulls values that wont show up in valid data\n",
    "        df = df.fillna('0000-00-00') \n",
    "\n",
    "        df['year'] = df.iloc[:,0].apply(lambda x: str(x)[:4])\n",
    "        df['month'] = df.iloc[:,0].apply(lambda x: str(x)[5:7])\n",
    "        df = df.astype({'year':'int64', 'month':'int64'})\n",
    "\n",
    "        return df.loc[:,['year','month']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mEjln8HzoyC"
   },
   "source": [
    "### Column Transformation\n",
    "Now let's combine all those transformations to create our pipeline. First, we create a pipeline to sequentially execute the steps for our categorical columns. Next, we define a `ColumnTransformer` which will apply the categorical transformations, date transformations, and will pass our other feature columns through into the final data. All other columns not specified here will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQJu-3Djy-dm"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Pipeline to create binary columns\n",
    "multilabel_binarizer_pipeline = Pipeline([\n",
    "    ('multilabel_str_to_array',MultiLabelStringToArray()),\n",
    "    ('binarizer', MultiLabelBinarizerTransformer()),\n",
    "],verbose=True)\n",
    "\n",
    "MULTILABEL_BINARIZER_COLUMNS = ['genres','production_countries', 'spoken_languages', 'gender', 'occupation']\n",
    "RELEASE_DATE_COLUMNS = ['release_date']\n",
    "PASSTHROUGH_COLUMNS = ['age','budget','popularity','revenue', 'runtime', 'vote_average', 'vote_count']\n",
    "\n",
    "full_data_clean_pipeline = ColumnTransformer([\n",
    "    ('multilabel_binarizer', multilabel_binarizer_pipeline, MULTILABEL_BINARIZER_COLUMNS),\n",
    "    ('release_date', ExtractReleaseDateFeatures(), RELEASE_DATE_COLUMNS),\n",
    "    ('passthrough_columns','passthrough', PASSTHROUGH_COLUMNS)\n",
    "],remainder='drop',verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1L5aoDhC0zP-"
   },
   "source": [
    "## Training\n",
    "With our pipeline setup, we are ready to try it out on some data. First, I combine all our raw data loaded from GitHub into a single DataFrame. Next, we sort the data based on `userid` because we want to train and test our model on different users, to see if what the model learned about one user's preferences apply to other users. Finally, I've decided to drop rows that contain nulls in columns that we are not applying transformations to. I chose to do this because there were only ~650 rows to which this applied. If there were more rows with null values I might consider a different approach because it could mean losing too much data. Another possibility is that there could be hidden meaning in the null values, such as null values being a proxy for old movies where that data could be harder to get. Either way, 650 rows is not even 1/100th of our data set so I'm not going to lose sleep over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "CX-gqq1w4YEM",
    "outputId": "58e5e372-3742-4cbf-98e0-bde7a022501a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18981</th>\n",
       "      <td>legends+of+the+fall+1994</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>['Adventure', 'Drama', 'Romance', 'War']</td>\n",
       "      <td>tt0110322</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>['Bedford Falls Productions', 'TriStar Picture...</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1994-12-16</td>\n",
       "      <td>160639000.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>['', 'English']</td>\n",
       "      <td>Legends of the Fall</td>\n",
       "      <td>4476.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18869</th>\n",
       "      <td>miracle+on+34th+street+1994</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Fantasy', 'Drama', 'Family']</td>\n",
       "      <td>tt0110527</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>['Twentieth Century Fox Film Corporation']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1994-11-18</td>\n",
       "      <td>46264400.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>['English']</td>\n",
       "      <td>Miracle on 34th Street</td>\n",
       "      <td>10510.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20104</th>\n",
       "      <td>four+weddings+and+a+funeral+1994</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>['Comedy', 'Drama', 'Romance']</td>\n",
       "      <td>tt0109831</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>['Channel Four Films', 'PolyGram Filmed Entert...</td>\n",
       "      <td>['United Kingdom']</td>\n",
       "      <td>1994-03-09</td>\n",
       "      <td>254701000.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>['English']</td>\n",
       "      <td>Four Weddings and a Funeral</td>\n",
       "      <td>712.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20117</th>\n",
       "      <td>jurassic+park+1993</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>63000000.0</td>\n",
       "      <td>['Adventure', 'Science Fiction']</td>\n",
       "      <td>tt0107290</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>['Universal Pictures', 'Amblin Entertainment']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1993-06-11</td>\n",
       "      <td>920100000.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['English', 'EspaÃ±ol']</td>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>329.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17547</th>\n",
       "      <td>braveheart+1995</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>72000000.0</td>\n",
       "      <td>['Action', 'Drama', 'History', 'War']</td>\n",
       "      <td>tt0112573</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>['Icon Entertainment International', 'The Ladd...</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>1995-05-24</td>\n",
       "      <td>210000000.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>['English', 'FranÃ§ais', 'Latin', '']</td>\n",
       "      <td>Braveheart</td>\n",
       "      <td>197.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3404.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie_id  rating  user_id  age gender  \\\n",
       "18981          legends+of+the+fall+1994       5        8   30      M   \n",
       "18869       miracle+on+34th+street+1994       4        8   30      M   \n",
       "20104  four+weddings+and+a+funeral+1994       4        8   30      M   \n",
       "20117                jurassic+park+1993       4        8   30      M   \n",
       "17547                   braveheart+1995       5        8   30      M   \n",
       "\n",
       "                 occupation      budget  \\\n",
       "18981  college/grad student  30000000.0   \n",
       "18869  college/grad student         0.0   \n",
       "20104  college/grad student   6000000.0   \n",
       "20117  college/grad student  63000000.0   \n",
       "17547  college/grad student  72000000.0   \n",
       "\n",
       "                                         genres    imdb_id original_language  \\\n",
       "18981  ['Adventure', 'Drama', 'Romance', 'War']  tt0110322                en   \n",
       "18869            ['Fantasy', 'Drama', 'Family']  tt0110527                en   \n",
       "20104            ['Comedy', 'Drama', 'Romance']  tt0109831                en   \n",
       "20117          ['Adventure', 'Science Fiction']  tt0107290                en   \n",
       "17547     ['Action', 'Drama', 'History', 'War']  tt0112573                en   \n",
       "\n",
       "       ...                               production_companies  \\\n",
       "18981  ...  ['Bedford Falls Productions', 'TriStar Picture...   \n",
       "18869  ...         ['Twentieth Century Fox Film Corporation']   \n",
       "20104  ...  ['Channel Four Films', 'PolyGram Filmed Entert...   \n",
       "20117  ...     ['Universal Pictures', 'Amblin Entertainment']   \n",
       "17547  ...  ['Icon Entertainment International', 'The Ladd...   \n",
       "\n",
       "               production_countries  release_date      revenue runtime  \\\n",
       "18981  ['United States of America']    1994-12-16  160639000.0   133.0   \n",
       "18869  ['United States of America']    1994-11-18   46264400.0   114.0   \n",
       "20104            ['United Kingdom']    1994-03-09  254701000.0   117.0   \n",
       "20117  ['United States of America']    1993-06-11  920100000.0   127.0   \n",
       "17547  ['United States of America']    1995-05-24  210000000.0   177.0   \n",
       "\n",
       "                           spoken_languages                        title  \\\n",
       "18981                       ['', 'English']          Legends of the Fall   \n",
       "18869                           ['English']       Miracle on 34th Street   \n",
       "20104                           ['English']  Four Weddings and a Funeral   \n",
       "20117                ['English', 'EspaÃ±ol']                Jurassic Park   \n",
       "17547  ['English', 'FranÃ§ais', 'Latin', '']                   Braveheart   \n",
       "\n",
       "       tmdb_id vote_average vote_count  \n",
       "18981   4476.0          7.2      636.0  \n",
       "18869  10510.0          6.4      199.0  \n",
       "20104    712.0          6.6      654.0  \n",
       "20117    329.0          7.6     4956.0  \n",
       "17547    197.0          7.7     3404.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = ratings_raw.join(users_raw, on='user_id', how='left')\n",
    "records = records.join(movies_raw, on='movie_id', how='left')\n",
    "\n",
    "records = records.sort_values(by=['user_id'])\n",
    "records = records.dropna(subset=['budget','popularity','revenue','runtime','vote_average','vote_count'])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sma5FEDQKLKX"
   },
   "source": [
    "Before we start playing around with TPOT we need to grab some train and test data. In this scenario, I'm going to put all my faith in TPOT to come up with the best model so I don't need to create a verification dataset. Let's start with a small amount of data just to see TPOT in action. First, we will fit and transform our dataset with the data cleaning pipeline we built then I'm going to select 10,000 records for both training and testing. We have a lot more data, but the more data there is the longer TPOT takes so, let's just start with 10k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "XPLJ2HGg5RUb",
    "outputId": "f9355a43-3fa8-4430-c6ae-a095f168d3d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 2) Processing multilabel_str_to_array, total=   9.9s\n",
      "[Pipeline] ......... (step 2 of 2) Processing binarizer, total=  20.5s\n",
      "[ColumnTransformer]  (1 of 3) Processing multilabel_binarizer, total=  31.8s\n",
      "[ColumnTransformer] .. (2 of 3) Processing release_date, total=   0.7s\n",
      "[ColumnTransformer]  (3 of 3) Processing passthrough_columns, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "X_all = full_data_clean_pipeline.fit_transform(records)\n",
    "y_all = records['rating']\n",
    "\n",
    "X_train = X_all[:10000]\n",
    "y_train = y_all[:10000]\n",
    "X_test = X_all[10000:20000]\n",
    "y_test = y_all[10000:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ause_3b5GooK"
   },
   "source": [
    "Now the time you've all been waiting for... afternoon tea (or whatever time of day you happen to be reading this). TPOT supports both regression and classification problems. I decided that this would be better as a regression problem because too many movies would tie for the top spot otherwise. \n",
    "Let's review some of the configuration options I chose:\n",
    "\n",
    "* `generations` - This is the number of iterations of pipeline generation that \n",
    "TPOT will run for. Alternatively, you could specify a `max_time_minutes` to stop TPOT after a certain amount of time.\n",
    "\n",
    "* `population_size` - This is the number of pipelines trained during each generation.\n",
    "\n",
    "* `verbosity` - This just gives us some feedback to let us know that TPOT is boiling away. It can take a long time I find this reassuring to make sure nothing is frozen. \n",
    "\n",
    "* `random_state` - This ensures that if we run this a second time we start with the same seed.\n",
    "\n",
    "* `template` - This describes how I want my pipeline to look. Since I have done little feature engineering I want to start with a Selector to find the best features, then transform those features and finally use a regressor. If I were to not specify a template TPOT would pick whatever combination worked best. In my trials, the shape of the pipeline would end up\n",
    "`Regressor-Regresssor-Regressor`.\n",
    "\n",
    "* `n_jobs` - The number of parallel processes to use for evaluation\n",
    "\n",
    "* `warm_start` - This tells TPOT whether to reuse populations from the last call to fit. This is good if you want to stop and restart the fit process.\n",
    "\n",
    "* `periodic_checkpoint_folder` - Where to intermittently save pipelines during the training. This can help make sure you get an output even if TPOT suddenly dies or you decide to stop the training early.\n",
    "\n",
    "For a full list of TPOT's configurations checkout their [documentation](https://epistasislab.github.io/tpot/api/).\n",
    "\n",
    "The configuration below will train 10,100 pipelines and compare them using 5-fold (another config options, but I just used the default) cross-validation and a negative mean squared error scoring function. It may not generate 10,100 unique pipelines; so, it will skip over any repeat pipelines that are generated. This example generates about 2,500 unique pipelines. \n",
    "\n",
    "**Warning:** This training takes about 6 hours to run. If you want to shorten the example you can change the `generations` and `population_size` to 10 and it will only generate 110 pipelines. This shorter process should take around 10 minutes to train.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492,
     "referenced_widgets": [
      "83571ce35bfc4fc3a451fc996c300c5e",
      "f38f05652fd142d0b392b49e87d5d53f",
      "5655f08e840e4f1799e4b64c84e03079",
      "a919fb4cf4c6449a9304779f2cb33632",
      "fd6d12341deb4108844e66110b0d126c",
      "316b11810f864f6bb236729bdb09a4e6",
      "426afa6951a7404c92e72634b6d28860",
      "ae6fc60b428d4c4d86fdcc7adf86f221"
     ]
    },
    "colab_type": "code",
    "id": "cEAVUfaB5x3J",
    "outputId": "c5184e17-d692-4caf-9257-73d1a8a3b688"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=110.0, style=ProgressStyle(deâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.9547903226888407\n",
      "Generation 2 - Current best internal CV score: -0.9547903226888407\n",
      "Generation 3 - Current best internal CV score: -0.952147120834435\n",
      "Generation 4 - Current best internal CV score: -0.94918041475317\n",
      "Generation 5 - Current best internal CV score: -0.94918041475317\n",
      "Generation 6 - Current best internal CV score: -0.94918041475317\n",
      "Generation 7 - Current best internal CV score: -0.9491529361806773\n",
      "Generation 8 - Current best internal CV score: -0.9491441900056168\n",
      "Generation 9 - Current best internal CV score: -0.9490030567432297\n",
      "Generation 10 - Current best internal CV score: -0.9490030567432297\n",
      "Best pipeline: LassoLarsCV(MaxAbsScaler(VarianceThreshold(input_matrix, threshold=0.0005)), normalize=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(generations=10,\n",
       "              log_file=<ipykernel.iostream.OutStream object at 0x103138f70>,\n",
       "              n_jobs=-1,\n",
       "              periodic_checkpoint_folder='../tpot-intermediate-save/',\n",
       "              population_size=10, random_state=42,\n",
       "              template='Selector-Transformer-Regressor', verbosity=2,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "pipeline_optimizer = TPOTRegressor(generations=10, population_size=10, verbosity=2, random_state=42,\n",
    "                                   template='Selector-Transformer-Regressor', n_jobs=-1,\n",
    "                                   warm_start=True, periodic_checkpoint_folder='../tpot-intermediate-save/')\n",
    "pipeline_optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVzjX8u1Qdux"
   },
   "source": [
    "## Evaluation\n",
    "Just like scikit-learn TPOT comes with a built-in evaluation mechanism. We can use the test data to evaluate our pipeline with the same scoring function that we used in training (we used the default which is negative mean squared error). We can see that our test data gives similar results as the cross validation scores seen during training. It looks like our model is off by almost a whole number in its predictions. This is likely in adequite for our scenario however, we would need to examine what sort of errors the model is making. For exmaple, if the model just estimates one point too low everytime then the model is perfect because we would recommend the correct movie; However, if the direction of error is variable it would cause some unfavorable movies to be recommended (at least personally the difference between a 3 and a 4 on a 5 point scale is enormous). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtTJbRVTKnRR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9941578822208572"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUBwraJ3OVXY"
   },
   "source": [
    "## More Data is Better (maybe)\n",
    "Since we have so much data and machine learning models are almost always better when trained on more data, let's use everything we've got. I'm going to split the data into 500k rows for training and the remaining ~240k for testings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7kFbftqS33p"
   },
   "outputs": [],
   "source": [
    "X_train_large = X_all[:500000]\n",
    "y_train_large = y_all[:500000]\n",
    "X_test_large = X_all[500000:]\n",
    "y_test_large = y_all[500000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoRToIZJUHDS"
   },
   "source": [
    "More is not always better. TPOT is already a timely process because there are so many pipelines generated and evaluated using k-fold cross-validation. The larger the dataset that the models are trained on, the longer this process is going to take. If you noticed I added one parameter to the configuration. `config_dict=\"TPOT light\"` tells TPOT that I am using a large data set so it will limit the model search to only model features that are simpler and fast running. Therefore, it finds a pipeline that works well for large datasets.\n",
    "\n",
    "**Warning**: This training takes somewhere between 12 and 20 hours to complete. Google Colab's runtime may timeout before you are complete. You may need to clone or fork my repo and use the [Jupyter Lab notebook](https://github.com/bialesdaniel/se4ai-i5-tpot/blob/master/notebooks/TPOT-Movies-Explained.ipynb) there to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "83a431c8ef5f4753b9233e0eb2a25eff",
      "e9a223ffadcb416bba1be446cf42a4ad",
      "cd55a8fa8fbe4aacadbd2dd0d616b985",
      "1d5b5b4bd42a40d8ba93b20a52d24b85",
      "e0c1e55c0cd64d2cabb1edbb9961af87",
      "a53d0fd47f4b453a8e7f6fd874bacd35",
      "1007e7fa995a4173aa988c4e882cada7",
      "1b94d26ccff94d37a844a3c76b791a8a"
     ]
    },
    "colab_type": "code",
    "id": "sSFnYDA3SbOc",
    "outputId": "600fef8e-fa0f-4c5c-dece-09b34b84deab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=110.0, style=ProgressStyle(deâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 2 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 3 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 4 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 5 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 6 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 7 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 8 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 9 - Current best internal CV score: -0.9833348958387484\n",
      "Generation 10 - Current best internal CV score: -0.9833323195498851\n",
      "Best pipeline: ElasticNetCV(StandardScaler(VarianceThreshold(input_matrix, threshold=0.0001)), l1_ratio=0.8, tol=0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict='TPOT light', generations=10,\n",
       "              log_file=<ipykernel.iostream.OutStream object at 0x103138f70>,\n",
       "              n_jobs=-1,\n",
       "              periodic_checkpoint_folder='../tpot-intermediate-save-large/',\n",
       "              population_size=10, random_state=42,\n",
       "              template='Selector-Transformer-Regressor', verbosity=2,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer_large = TPOTRegressor(generations=10, population_size=10, verbosity=2, random_state=42,\n",
    "                                      template='Selector-Transformer-Regressor', config_dict=\"TPOT light\", n_jobs=-1,\n",
    "                                     warm_start=True, periodic_checkpoint_folder='../tpot-intermediate-save-large/')\n",
    "pipeline_optimizer_large.fit(X_train_large, y_train_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPPJfcNUDcXg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9893467038216204"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer_large.score(X_test_large, y_test_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHbyS-mIW3hg"
   },
   "source": [
    "## Conclusions\n",
    "As we have seen, TPOT is quite easy to use.  The autoML process can save some valuable time and effort in feature engineering and hyperparameter tuning. On the other hand, TPOT is slow. It can take a long time to generate the optimal pipeline. \n",
    "\n",
    "Sorry, these conclusions are rather shallow because this notebook is mostly focused on how to set up and use TPOT for our movie recommendation system. For more in-depth analysis of the tool please continue reading the [Medium article]() from which you came."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TPOT-Movies-Explained.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1007e7fa995a4173aa988c4e882cada7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b94d26ccff94d37a844a3c76b791a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d5b5b4bd42a40d8ba93b20a52d24b85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b94d26ccff94d37a844a3c76b791a8a",
      "placeholder": "â",
      "style": "IPY_MODEL_1007e7fa995a4173aa988c4e882cada7",
      "value": " 12/550 [16:43&lt;34:30:13, 230.88s/pipeline]"
     }
    },
    "316b11810f864f6bb236729bdb09a4e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "426afa6951a7404c92e72634b6d28860": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5655f08e840e4f1799e4b64c84e03079": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Optimization Progress:   0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_316b11810f864f6bb236729bdb09a4e6",
      "max": 10100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd6d12341deb4108844e66110b0d126c",
      "value": 0
     }
    },
    "83571ce35bfc4fc3a451fc996c300c5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5655f08e840e4f1799e4b64c84e03079",
       "IPY_MODEL_a919fb4cf4c6449a9304779f2cb33632"
      ],
      "layout": "IPY_MODEL_f38f05652fd142d0b392b49e87d5d53f"
     }
    },
    "83a431c8ef5f4753b9233e0eb2a25eff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd55a8fa8fbe4aacadbd2dd0d616b985",
       "IPY_MODEL_1d5b5b4bd42a40d8ba93b20a52d24b85"
      ],
      "layout": "IPY_MODEL_e9a223ffadcb416bba1be446cf42a4ad"
     }
    },
    "a53d0fd47f4b453a8e7f6fd874bacd35": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a919fb4cf4c6449a9304779f2cb33632": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae6fc60b428d4c4d86fdcc7adf86f221",
      "placeholder": "â",
      "style": "IPY_MODEL_426afa6951a7404c92e72634b6d28860",
      "value": " 0/10100 [00:04&lt;?, ?pipeline/s]"
     }
    },
    "ae6fc60b428d4c4d86fdcc7adf86f221": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd55a8fa8fbe4aacadbd2dd0d616b985": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Optimization Progress:   2%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a53d0fd47f4b453a8e7f6fd874bacd35",
      "max": 550,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0c1e55c0cd64d2cabb1edbb9961af87",
      "value": 12
     }
    },
    "e0c1e55c0cd64d2cabb1edbb9961af87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e9a223ffadcb416bba1be446cf42a4ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f38f05652fd142d0b392b49e87d5d53f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd6d12341deb4108844e66110b0d126c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
